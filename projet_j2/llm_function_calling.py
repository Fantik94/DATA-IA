import requests
import json
import subprocess
import os
import time
from typing import Dict, Any, List

MISTRAL_API_KEY = "OHgvSY6RrhHNkTY1M3RQ7ici0iLuDwPv"
MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"

def generateText(prompt: str, force_json: bool = False, conversation_history: List[Dict] = None) -> str:
    """
    Fonction qui prend en entr√©e un prompt et envoie la requ√™te √† Mistral via leur API.
    
    Args:
        prompt (str): Le prompt √† envoyer au LLM
        force_json (bool): Si True, force le format JSON en sortie
        conversation_history (List[Dict]): Historique de la conversation
        
    Returns:
        str: La r√©ponse du LLM
    """
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Construire les messages avec l'historique
    messages = []
    
    # Ajouter l'historique s'il existe
    if conversation_history:
        messages.extend(conversation_history)
    
    # Ajouter le message actuel
    messages.append({
        "role": "user", 
        "content": prompt
    })
    
    data = {
        "model": "mistral-small-latest",
        "messages": messages,
        "max_tokens": 8000,  # Tokens augment√©s pour des r√©ponses plus longues
        "temperature": 0.7
    }
    
    # Ajouter le format JSON seulement si demand√©
    if force_json:
        data["response_format"] = {
            "type": "json_object"
        }
    
    try:
        response = requests.post(MISTRAL_API_URL, headers=headers, json=data)
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
        
    except requests.exceptions.RequestException as e:
        return f"Erreur lors de la requ√™te √† l'API Mistral: {e}"
    except KeyError as e:
        return f"Erreur lors du parsing de la r√©ponse: {e}"
    except Exception as e:
        return f"Erreur inattendue: {e}"


def writeFile(path: str, content: str) -> bool:
    """
    Fonction pour √©crire du contenu dans un fichier.
    
    Args:
        path (str): Le chemin du fichier √† cr√©er
        content (str): Le contenu √† √©crire
        
    Returns:
        bool: True si le fichier a √©t√© cr√©√© avec succ√®s, False sinon
    """
    try:
        directory = os.path.dirname(path)
        if directory:  # Seulement si le r√©pertoire n'est pas vide
            os.makedirs(directory, exist_ok=True)
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"Fichier cr√©√© avec succ√®s: {path}")
        return True
    except Exception as e:
        print(f"Erreur lors de la cr√©ation du fichier {path}: {e}")
        return False


def launchPythonFile(path: str) -> str:
    """
    Fonction pour ex√©cuter un fichier Python.
    
    Args:
        path (str): Le chemin du fichier Python √† ex√©cuter
        
    Returns:
        str: La sortie du programme ou un message d'erreur
    """
    try:
        result = subprocess.run(['python', path], 
                              capture_output=True, 
                              text=True, 
                              check=True)
        return f"Ex√©cution r√©ussie:\n{result.stdout}"
    except subprocess.CalledProcessError as e:
        return f"Erreur lors de l'ex√©cution: {e.stderr}"
    except FileNotFoundError:
        return f"Fichier non trouv√©: {path}"
    except Exception as e:
        return f"Erreur inattendue: {e}"


def choose_tool(context: str) -> str:
    """
    Fonction pour demander au LLM de choisir le prochain outil √† utiliser.
    
    Args:
        context (str): Le contexte actuel de la t√¢che
        
    Returns:
        str: Le nom de l'outil choisi ou des informations sur la d√©cision
    """
    return f"Outil s√©lectionn√© bas√© sur le contexte: {context}"


def stop(reason: str = "T√¢che termin√©e") -> Dict[str, Any]:
    """
    Fonction pour arr√™ter le processus d'it√©ration.
    
    Args:
        reason (str): La raison de l'arr√™t
        
    Returns:
        Dict: Informations sur l'arr√™t
    """
    return {
        "action": "stop",
        "reason": reason,
        "timestamp": time.time() if 'time' in globals() else None
    }


def iterative_function_calling_system(user_request: str, max_iterations: int = 5) -> Dict[str, Any]:
    """
    Syst√®me de function calling it√©ratif avec feedback et choix d'outils.
    
    Args:
        user_request (str): La demande initiale de l'utilisateur
        max_iterations (int): Nombre maximum d'it√©rations
        
    Returns:
        Dict: R√©sultat final avec historique des actions
    """
    conversation_history = []
    task_results = []
    iteration = 0
    
    print(f"üöÄ D√©marrage du syst√®me it√©ratif pour: {user_request}")
    print(f"üìä Maximum {max_iterations} it√©rations autoris√©es")
    
    while iteration < max_iterations:
        iteration += 1
        print(f"\n{'='*60}")
        print(f"üîÑ IT√âRATION {iteration}/{max_iterations}")
        print(f"{'='*60}")
        
        # Construire le contexte pour cette it√©ration
        context = build_iteration_context(user_request, conversation_history, task_results, iteration)
        
        # Demander au LLM de choisir la prochaine action
        action_result = choose_next_action(context)
        
        if not action_result.get("success"):
            print(f"‚ùå Erreur dans le choix d'action: {action_result.get('error')}")
            break
            
        chosen_action = action_result.get("action")
        action_args = action_result.get("arguments", {})
        
        print(f"üéØ Action choisie: {chosen_action}")
        print(f"üìã Arguments: {action_args}")
        
        # Ex√©cuter l'action choisie
        if chosen_action == "stop":
            print(f"üõë Arr√™t demand√©: {action_args.get('reason', 'T√¢che termin√©e')}")
            break
            
        elif chosen_action == "writeFile":
            result = writeFile(action_args.get("path"), action_args.get("content"))
            execution_result = {
                "success": result,
                "action": chosen_action,
                "details": f"Fichier {'cr√©√©' if result else 'non cr√©√©'}: {action_args.get('path')}"
            }
            
        elif chosen_action == "launchPythonFile":
            result = launchPythonFile(action_args.get("path"))
            execution_result = {
                "success": True,
                "action": chosen_action,
                "details": result
            }
            
        elif chosen_action == "choose_tool":
            result = choose_tool(action_args.get("context", ""))
            execution_result = {
                "success": True,
                "action": chosen_action,
                "details": result
            }
            
        else:
            execution_result = {
                "success": False,
                "action": chosen_action,
                "details": f"Action inconnue: {chosen_action}"
            }
        
        # Enregistrer les r√©sultats
        task_results.append(execution_result)
        conversation_history.append({
            "iteration": iteration,
            "user_request": user_request if iteration == 1 else "continuation",
            "chosen_action": chosen_action,
            "execution_result": execution_result
        })
        
        print(f"‚úÖ R√©sultat: {execution_result.get('details')}")
        
        # √âvaluer si on doit continuer
        if execution_result.get("success") and chosen_action in ["writeFile", "launchPythonFile"]:
            # Demander un feedback au LLM sur le r√©sultat
            feedback = get_feedback(execution_result, user_request, iteration)
            if feedback.get("should_continue", True):
                print(f"üí≠ Feedback: {feedback.get('message', 'Continuation...')}")
            else:
                print(f"‚ú® Feedback: {feedback.get('message', 'T√¢che accomplie!')}")
                break
    
    # R√©sultat final
    final_result = {
        "success": True,
        "total_iterations": iteration,
        "final_status": "completed" if iteration <= max_iterations else "max_iterations_reached",
        "conversation_history": conversation_history,
        "task_results": task_results,
        "user_request": user_request
    }
    
    print(f"\nüèÅ R√âSULTAT FINAL")
    print(f"üìä {iteration} it√©rations effectu√©es")
    print(f"‚úÖ Statut: {final_result['final_status']}")
    
    return final_result


def build_iteration_context(user_request: str, history: List, results: List, iteration: int) -> str:
    """Construit le contexte pour une it√©ration donn√©e"""
    context = f"""
DEMANDE UTILISATEUR INITIALE: {user_request}

IT√âRATION ACTUELLE: {iteration}

HISTORIQUE DES ACTIONS:
"""
    
    for i, entry in enumerate(history, 1):
        context += f"{i}. Action: {entry['chosen_action']} - R√©sultat: {entry['execution_result']['details']}\n"
    
    if not history:
        context += "Aucune action pr√©c√©dente.\n"
    
    context += f"""
T√ÇCHES DISPONIBLES:
1. writeFile(path, content) - √âcrire du contenu dans un fichier
2. launchPythonFile(path) - Ex√©cuter un fichier Python
3. choose_tool(context) - Choisir un outil sp√©cifique
4. stop(reason) - Arr√™ter le processus

Analysez la situation et choisissez la prochaine action appropri√©e.
"""
    
    return context


def choose_next_action(context: str) -> Dict[str, Any]:
    """Demande au LLM de choisir la prochaine action"""
    prompt = f"""
{context}

Vous devez choisir la prochaine action √† effectuer. R√©pondez UNIQUEMENT avec un JSON valide:

{{
    "action": "nom_de_l_action",
    "arguments": {{
        "param1": "valeur1",
        "param2": "valeur2"
    }},
    "reasoning": "Explication de votre choix"
}}

Actions possibles:
- writeFile: pour cr√©er/modifier un fichier
- launchPythonFile: pour ex√©cuter un script Python
- choose_tool: pour s√©lectionner un outil sp√©cifique
- stop: pour terminer le processus

Choisissez intelligemment en fonction du contexte et de l'objectif.
"""
    
    try:
        response = generateText(prompt, force_json=True)
        action_data = json.loads(response)
        
        return {
            "success": True,
            "action": action_data.get("action"),
            "arguments": action_data.get("arguments", {}),
            "reasoning": action_data.get("reasoning", "")
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur lors du choix d'action: {e}"
        }


def get_feedback(execution_result: Dict, user_request: str, iteration: int) -> Dict[str, Any]:
    """Obtient un feedback du LLM sur le r√©sultat d'une action"""
    prompt = f"""
DEMANDE UTILISATEUR: {user_request}
IT√âRATION: {iteration}
ACTION EX√âCUT√âE: {execution_result.get('action')}
R√âSULTAT: {execution_result.get('details')}

√âvaluez si cette action a bien progress√© vers l'objectif de l'utilisateur.
R√©pondez UNIQUEMENT avec un JSON valide:

{{
    "should_continue": true/false,
    "message": "Votre √©valuation et recommandation",
    "confidence": 0.8
}}

Si should_continue est false, cela signifie que la t√¢che est accomplie.
Si true, donnez des suggestions pour l'am√©lioration.
"""
    
    try:
        response = generateText(prompt, force_json=True)
        feedback_data = json.loads(response)
        
        return {
            "should_continue": feedback_data.get("should_continue", True),
            "message": feedback_data.get("message", ""),
            "confidence": feedback_data.get("confidence", 0.5)
        }
    except Exception as e:
        return {
            "should_continue": False,
            "message": f"Erreur feedback: {e}",
            "confidence": 0.0
        }


def function_calling_system(user_request: str) -> Dict[str, Any]:
    """
    Syst√®me de function calling qui demande au LLM de choisir une fonction √† ex√©cuter.
    
    Args:
        user_request (str): La demande de l'utilisateur
        
    Returns:
        Dict: R√©sultat de l'ex√©cution de la fonction
    """
    function_calling_prompt = f"""
Tu es un assistant qui peut ex√©cuter des fonctions. Tu as acc√®s aux fonctions suivantes:

1. writeFile(path, content) - √âcrit du contenu dans un fichier
   - path: le chemin du fichier (str)
   - content: le contenu √† √©crire (str)

2. launchPythonFile(path) - Ex√©cute un fichier Python
   - path: le chemin du fichier Python (str)

Demande de l'utilisateur: {user_request}

R√©ponds UNIQUEMENT avec un JSON valide dans ce format:
{{
    "function_name": "nom_de_la_fonction",
    "arguments": {{
        "param1": "valeur1",
        "param2": "valeur2"
    }}
}}

Si aucune fonction n'est appropri√©e, r√©ponds avec:
{{
    "function_name": "none",
    "arguments": {{}}
}}
"""
    
    # Obtenir la r√©ponse du LLM en format JSON natif
    llm_response = generateText(function_calling_prompt, force_json=True)
    print(f"R√©ponse du LLM: {llm_response}")
    
    try:
        # Parser directement la r√©ponse JSON (plus de nettoyage n√©cessaire !)
        function_call = json.loads(llm_response)
        function_name = function_call.get("function_name")
        arguments = function_call.get("arguments", {})
        
        # Ex√©cuter la fonction demand√©e
        if function_name == "writeFile":
            path = arguments.get("path")
            content = arguments.get("content")
            if path and content:
                success = writeFile(path, content)
                return {
                    "success": success,
                    "function": function_name,
                    "arguments": arguments,
                    "result": f"Fichier {'cr√©√©' if success else 'non cr√©√©'}: {path}"
                }
            else:
                return {
                    "success": False,
                    "error": "Arguments manquants pour writeFile (path, content)"
                }
        
        elif function_name == "launchPythonFile":
            path = arguments.get("path")
            if path:
                result = launchPythonFile(path)
                return {
                    "success": True,
                    "function": function_name,
                    "arguments": arguments,
                    "result": result
                }
            else:
                return {
                    "success": False,
                    "error": "Argument manquant pour launchPythonFile (path)"
                }
        
        elif function_name == "none":
            return {
                "success": True,
                "function": "none",
                "result": "Aucune fonction √† ex√©cuter"
            }
        
        else:
            return {
                "success": False,
                "error": f"Fonction inconnue: {function_name}"
            }
            
    except json.JSONDecodeError as e:
        return {
            "success": False,
            "error": f"Erreur lors du parsing JSON: {e}",
            "raw_response": llm_response
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur inattendue: {e}"
        }


def test_generateText():
    """Test de la fonction generateText"""
    print("=== Test de la fonction generateText ===")
    
    test_prompt = "Bonjour ! Peux-tu me dire une phrase simple pour tester ton fonctionnement ?"
    response = generateText(test_prompt)
    
    print(f"Prompt: {test_prompt}")
    print(f"R√©ponse: {response}")
    print()


def test_hello_world():
    """Test du function calling pour cr√©er un fichier hello world"""
    print("=== Test du function calling - Hello World ===")
    
    user_request = "√âcris un fichier Python appel√© 'hello_world.py' qui contient un simple print('Hello World')"
    
    result = function_calling_system(user_request)
    print(f"R√©sultat: {json.dumps(result, indent=2, ensure_ascii=False)}")
    
    # Si le fichier a √©t√© cr√©√©, essayons de l'ex√©cuter
    if result.get("success") and result.get("function") == "writeFile":
        print("\n=== Test d'ex√©cution du fichier cr√©√© ===")
        exec_result = function_calling_system("Ex√©cute le fichier hello_world.py")
        print(f"R√©sultat d'ex√©cution: {json.dumps(exec_result, indent=2, ensure_ascii=False)}")


if __name__ == "__main__":
    print("üöÄ D√©marrage du projet LLM Function Calling avec Mistral")
    print("=" * 60)
    
    # Test 1: Fonction generateText
    test_generateText()
    
    # Test 2: Function calling pour Hello World
    test_hello_world()
    
    print("=" * 60)
    print("‚úÖ") 