import json
import subprocess
import os
import time
import requests
import base64
from typing import Dict, Any, List
from dotenv import load_dotenv
from mistralai import Mistral
from bs4 import BeautifulSoup
from PIL import Image

load_dotenv()

api_key = os.environ["MISTRAL_API_KEY"]
client = Mistral(api_key=api_key)

def generateText(prompt: str, force_json: bool = False, conversation_history: List[Dict] = None) -> str:
    """
    Fonction qui prend en entr√©e un prompt et envoie la requ√™te √† Mistral via leur SDK.
    
    Args:
        prompt (str): Le prompt √† envoyer au LLM
        force_json (bool): Si True, force le format JSON en sortie
        conversation_history (List[Dict]): Historique de la conversation
        
    Returns:
        str: La r√©ponse du LLM
    """
    messages = []
    
    if conversation_history:
        messages.extend(conversation_history)
    
    messages.append({"role": "user", "content": prompt})
    
    try:
        kwargs = {
            "model": "mistral-small-latest",
            "messages": messages,
            "max_tokens": 8000,
            "temperature": 0.7
        }
        
        if force_json:
            kwargs["response_format"] = {"type": "json_object"}
        
        response = client.chat.complete(**kwargs)
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"Erreur lors de l'appel √† l'API Mistral: {e}"


def writeFile(path: str, content: str) -> bool:
    """
    Fonction pour √©crire du contenu dans un fichier.
    
    Args:
        path (str): Le chemin du fichier √† cr√©er
        content (str): Le contenu √† √©crire
        
    Returns:
        bool: True si le fichier a √©t√© cr√©√© avec succ√®s, False sinon
    """
    try:
        directory = os.path.dirname(path)
        if directory:  # Seulement si le r√©pertoire n'est pas vide
            os.makedirs(directory, exist_ok=True)
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"Fichier cr√©√© avec succ√®s: {path}")
        return True
    except Exception as e:
        print(f"Erreur lors de la cr√©ation du fichier {path}: {e}")
        return False


def launchPythonFile(path: str) -> str:
    """
    Fonction pour ex√©cuter un fichier Python.
    
    Args:
        path (str): Le chemin du fichier Python √† ex√©cuter
        
    Returns:
        str: La sortie du programme ou un message d'erreur
    """
    try:
        result = subprocess.run(['python', path], 
                              capture_output=True, 
                              text=True, 
                              check=True)
        return f"Ex√©cution r√©ussie:\n{result.stdout}"
    except subprocess.CalledProcessError as e:
        return f"Erreur lors de l'ex√©cution: {e.stderr}"
    except FileNotFoundError:
        return f"Fichier non trouv√©: {path}"
    except Exception as e:
        return f"Erreur inattendue: {e}"


def choose_tool(context: str) -> str:
    """
    Fonction pour demander au LLM de choisir le prochain outil √† utiliser.
    
    Args:
        context (str): Le contexte actuel de la t√¢che
        
    Returns:
        str: Le nom de l'outil choisi ou des informations sur la d√©cision
    """
    return f"Outil s√©lectionn√© bas√© sur le contexte: {context}"


def stop(reason: str = "T√¢che termin√©e") -> Dict[str, Any]:
    """
    Fonction pour arr√™ter le processus d'it√©ration.
    
    Args:
        reason (str): La raison de l'arr√™t
        
    Returns:
        Dict: Informations sur l'arr√™t
    """
    return {
        "action": "stop",
        "reason": reason,
        "timestamp": time.time() if 'time' in globals() else None
    }


def listFiles(directory: str = ".") -> Dict[str, Any]:
    """
    Liste les fichiers et dossiers d'un r√©pertoire.
    
    Args:
        directory (str): Le r√©pertoire √† explorer (par d√©faut le r√©pertoire courant)
        
    Returns:
        Dict: Informations sur les fichiers et dossiers
    """
    try:
        files = []
        directories = []
        
        for item in os.listdir(directory):
            item_path = os.path.join(directory, item)
            if os.path.isfile(item_path):
                size = os.path.getsize(item_path)
                files.append({
                    "name": item,
                    "path": item_path,
                    "size": size,
                    "extension": os.path.splitext(item)[1]
                })
            elif os.path.isdir(item_path):
                directories.append({
                    "name": item,
                    "path": item_path
                })
        
        return {
            "success": True,
            "directory": directory,
            "files": files,
            "directories": directories,
            "total_files": len(files),
            "total_directories": len(directories)
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur lors de la lecture du r√©pertoire {directory}: {e}"
        }


def readFile(file_path: str) -> Dict[str, Any]:
    """
    Lit le contenu d'un fichier existant.
    
    Args:
        file_path (str): Le chemin du fichier √† lire
        
    Returns:
        Dict: Le contenu du fichier et ses m√©tadonn√©es
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        file_stats = os.stat(file_path)
        
        return {
            "success": True,
            "file_path": file_path,
            "content": content,
            "lines": len(content.split('\n')),
            "size": file_stats.st_size,
            "extension": os.path.splitext(file_path)[1]
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur lors de la lecture du fichier {file_path}: {e}"
        }


def runTests(test_path: str = "test_*.py") -> Dict[str, Any]:
    """
    Ex√©cute des tests unitaires avec pytest.
    
    Args:
        test_path (str): Le chemin ou pattern des fichiers de test
        
    Returns:
        Dict: R√©sultat de l'ex√©cution des tests
    """
    try:
        result = subprocess.run(['python', '-m', 'pytest', test_path, '-v'], 
                              capture_output=True, 
                              text=True)
        
        return {
            "success": result.returncode == 0,
            "return_code": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "test_path": test_path
        }
    except FileNotFoundError:
        return {
            "success": False,
            "error": "pytest n'est pas install√©. Installez-le avec: pip install pytest"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur lors de l'ex√©cution des tests: {e}"
        }


def webScraping(url: str, selector: str = None) -> Dict[str, Any]:
    """
    Effectue du web scraping sur une URL donn√©e.
    
    Args:
        url (str): L'URL √† scraper
        selector (str): S√©lecteur CSS optionnel pour extraire des √©l√©ments sp√©cifiques
        
    Returns:
        Dict: Donn√©es scrap√©es
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        if selector:
            elements = soup.select(selector)
            data = [elem.get_text(strip=True) for elem in elements]
        else:
            data = {
                "title": soup.title.string if soup.title else "Pas de titre",
                "text_content": soup.get_text()[:1000],  # Premier 1000 caract√®res
                "links": [a.get('href') for a in soup.find_all('a', href=True)[:10]]
            }
        
        return {
            "success": True,
            "url": url,
            "data": data,
            "status_code": response.status_code
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur lors du scraping de {url}: {e}"
        }


def analyzeImage(image_path: str, prompt: str = "D√©cris cette image en d√©tail") -> Dict[str, Any]:
    """
    Analyse une image avec le mod√®le vision Pixtral de Mistral.
    
    Args:
        image_path (str): Le chemin vers l'image √† analyser
        prompt (str): La question/prompt pour l'analyse
        
    Returns:
        Dict: R√©sultat de l'analyse de l'image
    """
    try:
        # V√©rifier que le fichier image existe
        if not os.path.exists(image_path):
            return {
                "success": False,
                "error": f"Image non trouv√©e: {image_path}"
            }
        
        # Encoder l'image en base64
        with open(image_path, "rb") as image_file:
            encoded_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        # Pr√©parer les messages pour Pixtral
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": f"data:image/jpeg;base64,{encoded_image}"
                    }
                ]
            }
        ]
        
        # Appel √† Pixtral (mod√®le vision de Mistral)
        response = client.chat.complete(
            model="pixtral-12b-2409",
            messages=messages,
            max_tokens=1000
        )
        
        return {
            "success": True,
            "image_path": image_path,
            "prompt": prompt,
            "analysis": response.choices[0].message.content
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur lors de l'analyse de l'image {image_path}: {e}"
        }


def iterative_function_calling_system(user_request: str, max_iterations: int = 5) -> Dict[str, Any]:
    """
    Syst√®me de function calling it√©ratif avec feedback et choix d'outils.
    
    Args:
        user_request (str): La demande initiale de l'utilisateur
        max_iterations (int): Nombre maximum d'it√©rations
        
    Returns:
        Dict: R√©sultat final avec historique des actions
    """
    conversation_history = []
    task_results = []
    iteration = 0
    
    print(f"üöÄ D√©marrage du syst√®me it√©ratif pour: {user_request}")
    print(f"üìä Maximum {max_iterations} it√©rations autoris√©es")
    
    while iteration < max_iterations:
        iteration += 1
        print(f"\n{'='*60}")
        print(f"üîÑ IT√âRATION {iteration}/{max_iterations}")
        print(f"{'='*60}")
        
        context = build_iteration_context(user_request, conversation_history, task_results, iteration)
        
        action_result = choose_next_action(context)
        
        if not action_result.get("success"):
            print(f"‚ùå Erreur dans le choix d'action: {action_result.get('error')}")
            break
            
        chosen_action = action_result.get("action")
        action_args = action_result.get("arguments", {})
        
        print(f"üéØ Action choisie: {chosen_action}")
        print(f"üìã Arguments: {action_args}")
        
        if chosen_action == "stop":
            print(f"üõë Arr√™t demand√©: {action_args.get('reason', 'T√¢che termin√©e')}")
            break
            
        elif chosen_action == "writeFile":
            result = writeFile(action_args.get("path"), action_args.get("content"))
            execution_result = {
                "success": result,
                "action": chosen_action,
                "details": f"Fichier {'cr√©√©' if result else 'non cr√©√©'}: {action_args.get('path')}"
            }
            
        elif chosen_action == "launchPythonFile":
            result = launchPythonFile(action_args.get("path"))
            execution_result = {
                "success": True,
                "action": chosen_action,
                "details": result
            }
            
        elif chosen_action == "listFiles":
            result = listFiles(action_args.get("directory", "."))
            execution_result = {
                "success": result.get("success", False),
                "action": chosen_action,
                "details": f"Listage {'r√©ussi' if result.get('success') else '√©chou√©'}: {result.get('total_files', 0)} fichiers, {result.get('total_directories', 0)} dossiers" if result.get("success") else result.get("error")
            }
            
        elif chosen_action == "readFile":
            result = readFile(action_args.get("file_path"))
            execution_result = {
                "success": result.get("success", False),
                "action": chosen_action,
                "details": f"Lecture {'r√©ussie' if result.get('success') else '√©chou√©e'}: {result.get('lines', 0)} lignes" if result.get("success") else result.get("error")
            }
            
        elif chosen_action == "runTests":
            result = runTests(action_args.get("test_path", "test_*.py"))
            execution_result = {
                "success": result.get("success", False),
                "action": chosen_action,
                "details": f"Tests {'r√©ussis' if result.get('success') else '√©chou√©s'}: {result.get('stdout', result.get('stderr', ''))[:200]}"
            }
            
        elif chosen_action == "webScraping":
            result = webScraping(action_args.get("url"), action_args.get("selector"))
            execution_result = {
                "success": result.get("success", False),
                "action": chosen_action,
                "details": f"Scraping {'r√©ussi' if result.get('success') else '√©chou√©'}: {action_args.get('url')}" if result.get("success") else result.get("error")
            }
            
        elif chosen_action == "analyzeImage":
            result = analyzeImage(action_args.get("image_path"), action_args.get("prompt", "D√©cris cette image"))
            execution_result = {
                "success": result.get("success", False),
                "action": chosen_action,
                "details": f"Analyse {'r√©ussie' if result.get('success') else '√©chou√©e'}: {action_args.get('image_path')}" if result.get("success") else result.get("error")
            }
            
        elif chosen_action == "choose_tool":
            result = choose_tool(action_args.get("context", ""))
            execution_result = {
                "success": True,
                "action": chosen_action,
                "details": result
            }
            
        else:
            execution_result = {
                "success": False,
                "action": chosen_action,
                "details": f"Action inconnue: {chosen_action}"
            }
        
        task_results.append(execution_result)
        conversation_history.append({
            "iteration": iteration,
            "user_request": user_request if iteration == 1 else "continuation",
            "chosen_action": chosen_action,
            "execution_result": execution_result
        })
        
        print(f"‚úÖ R√©sultat: {execution_result.get('details')}")
        
        if execution_result.get("success") and chosen_action in ["writeFile", "launchPythonFile", "runTests"]:
            feedback = get_feedback(execution_result, user_request, iteration)
            if feedback.get("should_continue", True):
                print(f"üí≠ Feedback: {feedback.get('message', 'Continuation...')}")
            else:
                print(f"‚ú® Feedback: {feedback.get('message', 'T√¢che accomplie!')}")
                break
    
    final_result = {
        "success": True,
        "total_iterations": iteration,
        "final_status": "completed" if iteration <= max_iterations else "max_iterations_reached",
        "conversation_history": conversation_history,
        "task_results": task_results,
        "user_request": user_request
    }
    
    print(f"\nüèÅ R√âSULTAT FINAL")
    print(f"üìä {iteration} it√©rations effectu√©es")
    print(f"‚úÖ Statut: {final_result['final_status']}")
    
    return final_result


def build_iteration_context(user_request: str, history: List, results: List, iteration: int) -> str:
    """Construit le contexte pour une it√©ration donn√©e"""
    context = f"""
DEMANDE UTILISATEUR INITIALE: {user_request}

IT√âRATION ACTUELLE: {iteration}

HISTORIQUE DES ACTIONS:
"""
    
    for i, entry in enumerate(history, 1):
        context += f"{i}. Action: {entry['chosen_action']} - R√©sultat: {entry['execution_result']['details']}\n"
    
    if not history:
        context += "Aucune action pr√©c√©dente.\n"
    
    context += f"""
T√ÇCHES DISPONIBLES:
1. writeFile(path, content) - √âcrire du contenu dans un fichier
2. launchPythonFile(path) - Ex√©cuter un fichier Python
3. listFiles(directory) - Lister les fichiers d'un r√©pertoire
4. readFile(file_path) - Lire le contenu d'un fichier existant
5. runTests(test_path) - Ex√©cuter des tests unitaires avec pytest
6. webScraping(url, selector) - Faire du web scraping
7. analyzeImage(image_path, prompt) - Analyser une image avec Pixtral
8. stop(reason) - Arr√™ter le processus

Analysez la situation et choisissez la prochaine action appropri√©e.
"""
    
    return context


def choose_next_action(context: str) -> Dict[str, Any]:
    """Demande au LLM de choisir la prochaine action"""
    prompt = f"""
{context}

R√àGLES LOGIQUES √Ä SUIVRE :
1. Si un fichier doit √™tre cr√©√© ET ex√©cut√© : d'abord writeFile, puis launchPythonFile
2. Si un fichier existe d√©j√† et doit √™tre ex√©cut√© : utiliser launchPythonFile
3. Ne PAS recr√©er un fichier qui vient d'√™tre cr√©√© avec succ√®s
4. Si la t√¢che est accomplie, utiliser stop

R√©pondez UNIQUEMENT avec un JSON valide:

{{
    "action": "nom_de_l_action",
    "arguments": {{
        "param1": "valeur1",
        "param2": "valeur2"
    }},
    "reasoning": "Explication de votre choix"
}}

Actions possibles:
- writeFile: pour cr√©er/modifier un fichier (uniquement si pas encore cr√©√©)
- launchPythonFile: pour ex√©cuter un script Python (apr√®s cr√©ation)
- listFiles: pour explorer les fichiers du projet (utile pour comprendre la structure)
- readFile: pour lire le contenu d'un fichier existant (avant modification)
- runTests: pour ex√©cuter des tests unitaires avec pytest (v√©rifier que le code marche)
- webScraping: pour extraire des donn√©es depuis une URL
- analyzeImage: pour analyser des images avec l'IA vision Pixtral
- stop: pour terminer le processus quand tout est fait

R√àGLES SP√âCIALES POUR LES TESTS:
- Si vous cr√©ez du code, cr√©ez AUSSI les tests unitaires
- Utilisez runTests apr√®s cr√©ation de tests pour v√©rifier que tout fonctionne
- Nommez les fichiers de test avec le pr√©fixe 'test_'

Analysez l'historique pour voir ce qui a d√©j√† √©t√© fait et choisissez la PROCHAINE √©tape logique.
"""
    
    try:
        print(f"üîç Envoi du prompt au LLM...")
        response = generateText(prompt, force_json=True)
        print(f"üìù R√©ponse brute du LLM: '{response}'")
        
        if not response or response.strip() == "":
            print(f"‚ö†Ô∏è R√©ponse vide du LLM")
            return {
                "success": False,
                "error": "R√©ponse vide du LLM"
            }
            
        # Nettoyer la r√©ponse au cas o√π il y aurait des caract√®res parasites
        response = response.strip()
        if response.startswith("```json"):
            response = response[7:]
        if response.endswith("```"):
            response = response[:-3]
        response = response.strip()
        
        print(f"üßπ R√©ponse nettoy√©e: '{response}'")
        
        action_data = json.loads(response)
        
        return {
            "success": True,
            "action": action_data.get("action"),
            "arguments": action_data.get("arguments", {}),
            "reasoning": action_data.get("reasoning", "")
        }
    except json.JSONDecodeError as e:
        print(f"‚ùå Erreur JSON: {e}")
        print(f"‚ùå R√©ponse probl√©matique: '{response}'")
        return {
            "success": False,
            "error": f"Erreur JSON: {e} - R√©ponse: '{response[:100]}'"
        }
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")
        return {
            "success": False,
            "error": f"Erreur lors du choix d'action: {e}"
        }


def get_feedback(execution_result: Dict, user_request: str, iteration: int) -> Dict[str, Any]:
    """Obtient un feedback simplifi√© bas√© sur la logique"""
    action = execution_result.get('action')
    success = execution_result.get('success')
    
    # Analyse simple : si cr√©ation r√©ussie et demande d'ex√©cution, alors continuer
    if action == "writeFile" and success:
        if "execute" in user_request.lower() or "ex√©cute" in user_request.lower():
            return {
                "should_continue": True,
                "message": "Fichier cr√©√© avec succ√®s. Prochaine √©tape : ex√©cuter le fichier.",
                "confidence": 0.9
            }
        elif "test" in user_request.lower():
            return {
                "should_continue": True,
                "message": "Code cr√©√© avec succ√®s. Prochaine √©tape : cr√©er et ex√©cuter les tests.",
                "confidence": 0.9
            }
        else:
            return {
                "should_continue": False,
                "message": "Fichier cr√©√© avec succ√®s. T√¢che accomplie.",
                "confidence": 0.9
            }
    
    # Si ex√©cution r√©ussie, arr√™ter sauf si tests demand√©s
    elif action == "launchPythonFile" and success:
        if "test" in user_request.lower():
            return {
                "should_continue": True,
                "message": "Code ex√©cut√© avec succ√®s. Prochaine √©tape : cr√©er les tests unitaires.",
                "confidence": 0.9
            }
        else:
            return {
                "should_continue": False,
                "message": "Fichier ex√©cut√© avec succ√®s. T√¢che accomplie.",
                "confidence": 0.9
            }
    
    # Si tests ex√©cut√©s avec succ√®s, arr√™ter
    elif action == "runTests" and success:
        return {
            "should_continue": False,
            "message": "Tests ex√©cut√©s avec succ√®s. Code v√©rifi√© et valid√© !",
            "confidence": 0.9
        }
    
    # Si √©chec, continuer pour r√©essayer
    elif not success:
        return {
            "should_continue": True,
            "message": f"√âchec de l'action {action}. R√©essayer.",
            "confidence": 0.7
        }
    
    # Par d√©faut, arr√™ter apr√®s quelques it√©rations
    else:
        return {
            "should_continue": iteration < 2,
            "message": "Action termin√©e.",
            "confidence": 0.5
        }


def function_calling_system(user_request: str) -> Dict[str, Any]:
    """
    Syst√®me de function calling qui demande au LLM de choisir une fonction √† ex√©cuter.
    
    Args:
        user_request (str): La demande de l'utilisateur
        
    Returns:
        Dict: R√©sultat de l'ex√©cution de la fonction
    """
    function_calling_prompt = f"""
Tu es un assistant qui peut ex√©cuter des fonctions. Tu as acc√®s aux fonctions suivantes:

1. writeFile(path, content) - √âcrit du contenu dans un fichier
   - path: le chemin du fichier (str)
   - content: le contenu √† √©crire (str)

2. launchPythonFile(path) - Ex√©cute un fichier Python
   - path: le chemin du fichier Python (str)

Demande de l'utilisateur: {user_request}

R√©ponds UNIQUEMENT avec un JSON valide dans ce format:
{{
    "function_name": "nom_de_la_fonction",
    "arguments": {{
        "param1": "valeur1",
        "param2": "valeur2"
    }}
}}

Si aucune fonction n'est appropri√©e, r√©ponds avec:
{{
    "function_name": "none",
    "arguments": {{}}
}}
"""
    
    llm_response = generateText(function_calling_prompt, force_json=True)
    print(f"R√©ponse du LLM: {llm_response}")
    
    try:
        function_call = json.loads(llm_response)
        function_name = function_call.get("function_name")
        arguments = function_call.get("arguments", {})
        
        if function_name == "writeFile":
            path = arguments.get("path")
            content = arguments.get("content")
            if path and content:
                success = writeFile(path, content)
                return {
                    "success": success,
                    "function": function_name,
                    "arguments": arguments,
                    "result": f"Fichier {'cr√©√©' if success else 'non cr√©√©'}: {path}"
                }
            else:
                return {
                    "success": False,
                    "error": "Arguments manquants pour writeFile (path, content)"
                }
        
        elif function_name == "launchPythonFile":
            path = arguments.get("path")
            if path:
                result = launchPythonFile(path)
                return {
                    "success": True,
                    "function": function_name,
                    "arguments": arguments,
                    "result": result
                }
            else:
                return {
                    "success": False,
                    "error": "Argument manquant pour launchPythonFile (path)"
                }
        
        elif function_name == "none":
            return {
                "success": True,
                "function": "none",
                "result": "Aucune fonction √† ex√©cuter"
            }
        
        else:
            return {
                "success": False,
                "error": f"Fonction inconnue: {function_name}"
            }
            
    except json.JSONDecodeError as e:
        return {
            "success": False,
            "error": f"Erreur lors du parsing JSON: {e}",
            "raw_response": llm_response
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Erreur inattendue: {e}"
        }


def test_generateText():
    """Test de la fonction generateText"""
    print("=== Test de la fonction generateText ===")
    
    test_prompt = "Bonjour ! Peux-tu me dire une phrase simple pour tester ton fonctionnement ?"
    response = generateText(test_prompt)
    
    print(f"Prompt: {test_prompt}")
    print(f"R√©ponse: {response}")
    print()


def test_hello_world():
    """Test du function calling pour cr√©er un fichier hello world"""
    print("=== Test du function calling - Hello World ===")
    
    user_request = "√âcris un fichier Python appel√© 'hello_world.py' qui contient un simple print('Hello World')"
    
    result = function_calling_system(user_request)
    print(f"R√©sultat: {json.dumps(result, indent=2, ensure_ascii=False)}")
    
    # Si le fichier a √©t√© cr√©√©, essayons de l'ex√©cuter
    if result.get("success") and result.get("function") == "writeFile":
        print("\n=== Test d'ex√©cution du fichier cr√©√© ===")
        exec_result = function_calling_system("Ex√©cute le fichier hello_world.py")
        print(f"R√©sultat d'ex√©cution: {json.dumps(exec_result, indent=2, ensure_ascii=False)}")


if __name__ == "__main__":
    print("üöÄ D√©marrage du projet LLM Function Calling avec Mistral")
    print("=" * 60)
    
    # Test 1: Fonction generateText
    test_generateText()
    
    # Test 2: Function calling pour Hello World
    test_hello_world()
    
    print("=" * 60)
    print("‚úÖ") 